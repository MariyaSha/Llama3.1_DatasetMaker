{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llama3.1 Dataset Maker for Nvidia NIM\n",
    "\n",
    "This notebook is intended to run in a Llama3.1 NIM environment.\n",
    "<br>\n",
    "To set it up, please watch my video tutorial on the topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Llama3.1 NIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /root/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credential-stores\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "~/verb-workspace/loras ~/verb-workspace\n",
      "~/verb-workspace\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unable to find image 'nvcr.io/nim/meta/llama-3.1-8b-instruct:1.1.0' locally\n",
      "1.1.0: Pulling from nim/meta/llama-3.1-8b-instruct\n",
      "cbe3537751ce: Pulling fs layer\n",
      "d67fcc6ef577: Pulling fs layer\n",
      "47ee674c5713: Pulling fs layer\n",
      "63daa0e64b30: Pulling fs layer\n",
      "d9d9aecefab5: Pulling fs layer\n",
      "b377c960b7f3: Pulling fs layer\n",
      "071105f39313: Pulling fs layer\n",
      "18049dd7c352: Pulling fs layer\n",
      "071c1099eccd: Pulling fs layer\n",
      "161ecdfb16f0: Pulling fs layer\n",
      "fcfb2ec1ba22: Pulling fs layer\n",
      "154e691e00a7: Pulling fs layer\n",
      "9d18af386bf6: Pulling fs layer\n",
      "f1d9f7beba6e: Pulling fs layer\n",
      "0c951f04c367: Pulling fs layer\n",
      "fb6fbd97005b: Pulling fs layer\n",
      "431acb0bc035: Pulling fs layer\n",
      "38697a17baff: Pulling fs layer\n",
      "f9aeba7169f2: Pulling fs layer\n",
      "cfc9a1f4fc10: Pulling fs layer\n",
      "cfdd2bb2b4a6: Pulling fs layer\n",
      "c396a58289c6: Pulling fs layer\n",
      "63daa0e64b30: Waiting\n",
      "e8839de7b7ae: Pulling fs layer\n",
      "7941e23182d8: Pulling fs layer\n",
      "d9d9aecefab5: Waiting\n",
      "0372c9b9cb47: Pulling fs layer\n",
      "161ecdfb16f0: Waiting\n",
      "b377c960b7f3: Waiting\n",
      "dfedf8154b02: Pulling fs layer\n",
      "071105f39313: Waiting\n",
      "659b21d9411d: Pulling fs layer\n",
      "fcfb2ec1ba22: Waiting\n",
      "154e691e00a7: Waiting\n",
      "18049dd7c352: Waiting\n",
      "160151d7ae7f: Pulling fs layer\n",
      "071c1099eccd: Waiting\n",
      "fa2e0b787aaa: Pulling fs layer\n",
      "cfc9a1f4fc10: Waiting\n",
      "7941e23182d8: Waiting\n",
      "cfdd2bb2b4a6: Waiting\n",
      "9d18af386bf6: Waiting\n",
      "0372c9b9cb47: Waiting\n",
      "c396a58289c6: Waiting\n",
      "f1d9f7beba6e: Waiting\n",
      "dfedf8154b02: Waiting\n",
      "e8839de7b7ae: Waiting\n",
      "0c951f04c367: Waiting\n",
      "431acb0bc035: Waiting\n",
      "659b21d9411d: Waiting\n",
      "fa2e0b787aaa: Waiting\n",
      "160151d7ae7f: Waiting\n",
      "f9aeba7169f2: Waiting\n",
      "fb6fbd97005b: Waiting\n",
      "38697a17baff: Waiting\n",
      "d67fcc6ef577: Verifying Checksum\n",
      "d67fcc6ef577: Download complete\n",
      "63daa0e64b30: Verifying Checksum\n",
      "63daa0e64b30: Download complete\n",
      "cbe3537751ce: Verifying Checksum\n",
      "cbe3537751ce: Download complete\n",
      "47ee674c5713: Verifying Checksum\n",
      "47ee674c5713: Download complete\n",
      "d9d9aecefab5: Download complete\n",
      "b377c960b7f3: Download complete\n",
      "071c1099eccd: Verifying Checksum\n",
      "071c1099eccd: Download complete\n",
      "cbe3537751ce: Pull complete\n",
      "071105f39313: Verifying Checksum\n",
      "071105f39313: Download complete\n",
      "fcfb2ec1ba22: Verifying Checksum\n",
      "fcfb2ec1ba22: Download complete\n",
      "154e691e00a7: Verifying Checksum\n",
      "154e691e00a7: Download complete\n",
      "9d18af386bf6: Download complete\n",
      "f1d9f7beba6e: Download complete\n",
      "0c951f04c367: Verifying Checksum\n",
      "0c951f04c367: Download complete\n",
      "d67fcc6ef577: Pull complete\n",
      "fb6fbd97005b: Download complete\n",
      "431acb0bc035: Download complete\n",
      "18049dd7c352: Verifying Checksum\n",
      "18049dd7c352: Download complete\n",
      "38697a17baff: Verifying Checksum\n",
      "38697a17baff: Download complete\n",
      "f9aeba7169f2: Verifying Checksum\n",
      "f9aeba7169f2: Download complete\n",
      "cfdd2bb2b4a6: Download complete\n",
      "cfc9a1f4fc10: Download complete\n",
      "c396a58289c6: Verifying Checksum\n",
      "c396a58289c6: Download complete\n",
      "e8839de7b7ae: Verifying Checksum\n",
      "e8839de7b7ae: Download complete\n",
      "47ee674c5713: Pull complete\n",
      "63daa0e64b30: Pull complete\n",
      "d9d9aecefab5: Pull complete\n",
      "b377c960b7f3: Pull complete\n",
      "7941e23182d8: Verifying Checksum\n",
      "7941e23182d8: Download complete\n",
      "0372c9b9cb47: Verifying Checksum\n",
      "0372c9b9cb47: Download complete\n",
      "659b21d9411d: Download complete\n",
      "dfedf8154b02: Verifying Checksum\n",
      "dfedf8154b02: Download complete\n",
      "160151d7ae7f: Verifying Checksum\n",
      "160151d7ae7f: Download complete\n",
      "fa2e0b787aaa: Verifying Checksum\n",
      "fa2e0b787aaa: Download complete\n",
      "071105f39313: Pull complete\n",
      "18049dd7c352: Pull complete\n",
      "071c1099eccd: Pull complete\n",
      "161ecdfb16f0: Verifying Checksum\n",
      "161ecdfb16f0: Download complete\n",
      "161ecdfb16f0: Pull complete\n",
      "fcfb2ec1ba22: Pull complete\n",
      "154e691e00a7: Pull complete\n",
      "9d18af386bf6: Pull complete\n",
      "f1d9f7beba6e: Pull complete\n",
      "0c951f04c367: Pull complete\n",
      "fb6fbd97005b: Pull complete\n",
      "431acb0bc035: Pull complete\n",
      "38697a17baff: Pull complete\n",
      "f9aeba7169f2: Pull complete\n",
      "cfc9a1f4fc10: Pull complete\n",
      "cfdd2bb2b4a6: Pull complete\n",
      "c396a58289c6: Pull complete\n",
      "e8839de7b7ae: Pull complete\n",
      "7941e23182d8: Pull complete\n",
      "0372c9b9cb47: Pull complete\n",
      "dfedf8154b02: Pull complete\n",
      "659b21d9411d: Pull complete\n",
      "160151d7ae7f: Pull complete\n",
      "fa2e0b787aaa: Pull complete\n",
      "Digest: sha256:5dbfefe3788551319db70a63607089d4bd1aab4d05940402ab75d6ea5e3d3467\n",
      "Status: Downloaded newer image for nvcr.io/nim/meta/llama-3.1-8b-instruct:1.1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aeacfb0620ecfb3eec8141e58f5afbabce74e0e0e527b87e21e35935116ddb1e\n",
      "Checking if NIM is up...\n",
      "NIM is not up yet. Checking again in 10 seconds...\n",
      "NIM is not up yet. Checking again in 10 seconds...\n",
      "NIM is not up yet. Checking again in 10 seconds...\n",
      "NIM is not up yet. Checking again in 10 seconds...\n",
      "NIM is not up yet. Checking again in 10 seconds...\n",
      "NIM is not up yet. Checking again in 10 seconds...\n",
      "NIM is not up yet. Checking again in 10 seconds...\n",
      "NIM is not up yet. Checking again in 10 seconds...\n",
      "NIM is not up yet. Checking again in 10 seconds...\n",
      "NIM is not up yet. Checking again in 10 seconds...\n",
      "NIM is not up yet. Checking again in 10 seconds...\n",
      "NIM is not up yet. Checking again in 10 seconds...\n",
      "NIM is not up yet. Checking again in 10 seconds...\n",
      "NIM is not up yet. Checking again in 10 seconds...\n",
      "NIM is not up yet. Checking again in 10 seconds...\n",
      "NIM is not up yet. Checking again in 10 seconds...\n",
      "NIM is not up yet. Checking again in 10 seconds...\n",
      "NIM is not up yet. Checking again in 10 seconds...\n",
      "NIM is not up yet. Checking again in 10 seconds...\n",
      "NIM is not up yet. Checking again in 10 seconds...\n",
      "NIM is not up yet. Checking again in 10 seconds...\n",
      "NIM is not up yet. Checking again in 10 seconds...\n",
      "NIM is not up yet. Checking again in 10 seconds...\n",
      "NIM is not up yet. Checking again in 10 seconds...\n",
      "NIM has been started successfully!\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "\n",
    "export NGC_API_KEY= # paste your NGC API KEY here\n",
    "\n",
    "# Log in to NGC\n",
    "echo \"${NGC_API_KEY}\" | docker login nvcr.io -u '$oauthtoken' --password-stdin\n",
    "\n",
    "# Set path to your LoRA model store\n",
    "export LOCAL_PEFT_DIRECTORY=\"$(pwd)/loras\"\n",
    "mkdir -p $LOCAL_PEFT_DIRECTORY\n",
    "pushd $LOCAL_PEFT_DIRECTORY\n",
    "popd\n",
    "\n",
    "chmod -R 777 $LOCAL_PEFT_DIRECTORY\n",
    "\n",
    "# Set up NIM cache directory\n",
    "mkdir -p $HOME/.nim-cache\n",
    "\n",
    "export NIM_PEFT_SOURCE=/workspace/loras # Path to LoRA models internal to the container\n",
    "export CONTAINER_NAME=meta-llama3_1-8b-instruct\n",
    "export NIM_CACHE_PATH=$HOME/.nim-cache\n",
    "export NIM_PEFT_REFRESH_INTERVAL=60\n",
    "\n",
    "docker run -d --name=$CONTAINER_NAME \\\n",
    "    --network=container:verb-workspace \\\n",
    "    --runtime=nvidia \\\n",
    "    --gpus all \\\n",
    "    --shm-size=16GB \\\n",
    "    -e NGC_API_KEY \\\n",
    "    -e NIM_PEFT_SOURCE \\\n",
    "    -e NIM_PEFT_REFRESH_INTERVAL \\\n",
    "    -v $HOME/.nim-cache:/home/user/.nim-cache \\\n",
    "    -v /home/ubuntu/workspace:/workspace \\\n",
    "    -w /workspace \\\n",
    "    nvcr.io/nim/meta/llama-3.1-8b-instruct:1.1.0\n",
    "\n",
    "# Check if NIM is up\n",
    "echo \"Checking if NIM is up...\"\n",
    "while true; do\n",
    "    if curl -s http://localhost:8000 > /dev/null; then\n",
    "        echo \"NIM has been started successfully!\"\n",
    "        break\n",
    "    else\n",
    "        echo \"NIM is not up yet. Checking again in 10 seconds...\"\n",
    "        sleep 10\n",
    "    fi\n",
    "done\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify that Llama is Available\n",
    "Specify the client URL to check if Llama3.1 is listening on port 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"object\":\"health.response\",\"message\":\"Service is ready.\"}"
     ]
    }
   ],
   "source": [
    "!curl localhost:8000/v1/health/ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install OpenAI\n",
    "To run the dataset maker, the openai modeule is required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting openai\n",
      "  Downloading openai-1.40.4-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (4.4.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.4)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.62.3)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)\n",
      "Downloading openai-1.40.4-py3-none-any.whl (361 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m361.3/361.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: jiter, distro, openai\n",
      "Successfully installed distro-1.9.0 jiter-0.5.0 openai-1.40.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset\n",
    "\n",
    "In the following cell, you will see how to chain prompt output to generate datasets automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "\n",
    "# create empty dataframe \n",
    "data = pd.DataFrame(columns=[\"country\", \"capital\", \"food\"])\n",
    "\n",
    "# specify model location\n",
    "client = OpenAI(\n",
    "  base_url = \"http://localhost:8000/v1\",\n",
    "  api_key = \"not_used\"\n",
    ")\n",
    "\n",
    "def ask_question(user_input):\n",
    "    \n",
    "    # specify model settings\n",
    "    chat_response = client.chat.completions.create(\n",
    "    # please note: model name written without a dot symbol in this implementation\n",
    "    model=\"meta/llama-3_1-8b-instruct\",\n",
    "    messages=[{\"role\":\"user\",\"content\": user_input}],\n",
    "    temperature=0.5,\n",
    "    top_p=1,\n",
    "    max_tokens=1024,\n",
    "    # return output as a single unit of text\n",
    "    stream=False\n",
    "    )\n",
    "\n",
    "    return chat_response.choices[0].message.content\n",
    "\n",
    "# fetch names of all world countries\n",
    "all_countries = ask_question(\"\"\"\n",
    "names of all countries separated by commas in an alphabetical order.\n",
    "names only, with no other output\n",
    "\"\"\")\n",
    "all_countries = all_countries.split(\", \")\n",
    "\n",
    "# iterate over all country names\n",
    "for i, country in enumerate(all_countries):\n",
    "    # fetch attributes for each country\n",
    "    capital = ask_question(\"what is the capital city of \" + country + \". just the name\")\n",
    "    food = ask_question(\"what is the national food of \" + country + \". just the name\")\n",
    "    # store country and attributes in the pre-defined dataframe\n",
    "    data.loc[i] = [country, capital, food]\n",
    "\n",
    "# save CSV file in the current directory\n",
    "data.to_csv(\"data.csv\", header=None)\n",
    "print(\"CSV file was successully saved in the root directory of your Jupyter Lab! :)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
